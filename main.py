from typing import Set, List

import requests
import re
import datetime

BASE_URL = 'https://no-more-jockeys.fandom.com'


class Round(object):
    round_no: int
    player: str
    name: str
    category: str
    name_another: str
    challenged: bool
    game_page: str
    played: datetime

    def __init__(self, row_str: str, page_slug: str, played: datetime):
        entries = row_str.replace('</td><td>', '\n').replace('<td>', '').replace('</td>', '').split('\n')
        self.round_no = int(entries[0])
        self.player = entries[1]
        self.name = self.convert_name(entries[2])
        self.category = entries[3]
        self.name_another = entries[4]
        self.game_page = page_slug.replace('_', ' ')
        self.challenged = "✔" in entries[5]
        self.played = played

    def convert_name(self, name_html_str: str) -> str:
        return name_html_str.replace('<a target="_blank" rel="nofollow noreferrer noopener" class="external text" href="', '[')\
            .replace('">', ' ').replace('</a>', ']')

    def get_play_summary(self) -> str:
        starting_str = f'{self.player}: [[{self.game_page}|{self.game_page}]]'
        if self.challenged:
            starting_str += ' ✘'
        return starting_str

    def __str__(self):
        return f'#{self.round_no} - {self.player}: {self.name}'


def get_game_pages() -> Set[str]:
    result = requests.get(f'{BASE_URL}').text

    matches: List[str] = re.findall(r'(<td><a href="/wiki/(.*)" title=".*">)', result)
    all_pages: Set[str] = set()
    for match in matches:
        page_slug = match[1]
        all_pages.add(page_slug)

    #  print('\n'.join(all_pages))

    return all_pages


def parse_plays(page_slug: str, player_to_plays: dict[str, List[Round]]):
    result = requests.get(f'{BASE_URL}/wiki/{page_slug}').text.replace('\n', '')
    recorded_str = re.search(r'<h3 class="pi-data-label pi-secondary-font">Recorded</h3>		<div class="pi-data-value pi-font">([0-9/]+)</div>', result).group(1)
    recorded = datetime.datetime.strptime(recorded_str, "%d/%m/%Y")
    table = re.search(r'<tbody>(.*)</tbody>', result).group(1)
    rows = table.replace('</tr><tr>', '\n').replace('<tr>', '').replace('</tr>', '').split('\n')
    rows.pop(0)
    parsed_rounds = [Round(row, page_slug, recorded) for row in rows]
    for round in parsed_rounds:
        existing_list = player_to_plays.get(round.name, [])
        existing_list.append(round)
        existing_list = sorted(existing_list, key=lambda item: item.played)
        player_to_plays[round.name] = existing_list


def get_play_summary(plays: List[Round]) -> str:
    return '\n\n'.join([play.get_play_summary() for play in plays])


if __name__ == '__main__':
    pages = get_game_pages()

    player_to_plays: dict[str, List[Round]] = {}

    for page in pages:
        parse_plays(page, player_to_plays)

    sorted_plays = dict(sorted(player_to_plays.items(), key=lambda item: -len(item[1])))

    results_table_str = '{| class="article-table sortable"\n|+All Names\n!Name\n!Count\n!Games\n'

    for item in sorted_plays.items():
        name = item[0]
        count = len(item[1])
        plays = get_play_summary(item[1])
        results_table_str += f'|-\n|{name}\n|{count}\n|{plays}\n'

    results_table_str += '|}'

    page_source_str = f'This table has been [https://github.com/alexburlton/jockey-scraper auto-generated] by scraping {len(pages)} ' \
                      f'[[:Category:Game|game pages]] from this wiki - please do not edit it manually. The page can be ' \
                      f'regenerated by running the code again as more games are added.\n<br /><br />' \
                      f'\nIn total, \'\'\'{len(sorted_plays)} unique people\'\'\' have been named\n<br />\n {results_table_str}'

    print(page_source_str)
